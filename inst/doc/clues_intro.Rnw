
%
% NOTE -- ONLY EDIT THE .Rnw FILE!!!  The .tex file is
% likely to be overwritten.
%

%\VignetteIndexEntry{Introduction to CLUES Package}
%\VignetteDepends{stats, utils}
%\VignetteKeywords{clustering}
%\VignettePackage{clues}

\documentclass[12pt]{article}
\usepackage{times}
\usepackage{hyperref}

\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rpackage}[1]{{\textit{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{{\textit{#1}}}
\newcommand{\R}{\textsf{R}}

\textwidth=6.2in
\textheight=8.5in
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in
\def\refer{\smallbreak
     \hangindent 2pc \noindent}

\begin{document}
\title{ Introduction to \Rpackage{CLUES} Package }
\author{Fang Chang\\York University 
\and Vincent Carey\\Harvard Medical
School 
\and Weiliang Qiu\\Harvard Medical
School \and Ruben H. Zamar\\University of British Columbia \and Ross
Lazarus\\Harvard Medical School \and Xiaogang Wang\\York University}
\date{November 14, 2009}
\maketitle


\section{Introduction}

We introduce a novel \R{} package \Rpackage{clues} which provides 
a clustering methodology with no prior information on number of clusters 
required. Shrinking procedure, partition procedure and determination of 
the optimal number of groups are three mainstreams of the algorithm.
The functions in \Rpackage{clues} have the capability of locating optimal 
number of partitions according to the strength measures, either CH or Silhouette index. 
Additionally, in order to assess the performance of clustering 
methods, functions that are computing agreement indices 
(Rand index, Hubert and Arabie's adjusted Rand index, 
Morey and Agresti's adjusted Rand index, 
Fowlkes and Mallows index and Jaccard index)
for any two partitions are also provided.

\section{An Illustrative Application to Iris Data}

In this section, for the purpose of illustrating the usage of 
\Rpackage{clues}, we borrow the Fisher/Anderson \Robject{iris} dataset included in base \R{}.
This data set is of 
dimension $150 \times 5$ with 4 variables being sepal length and width and petal length and width.
The data present results for $3$ balanced species in order, 
``setosa'', ``versicolor'' and ``virginica''. 
First we invoke this package by inputting the following command at \R{} Console.

<<results=tex>>=
library("clues")
@


We take a glance of the data and examine its pair-wise scatter plot for 
the original data which is given in Figure~\ref{fig1}. 
<<>>=
data("iris")
head(iris)
dat.s <- as.matrix(iris[, -5])
colnames(dat.s) <- c("SL", "SW", "PL", "PW")
@
\begin{figure}[ht]
  \centering
<<fig=TRUE,width=8,height=8>>=
pairs(dat.s)
@
  \caption{Pairwise scatter plots for original iris data}
  \label{fig1}
\end{figure}

There are two clear groups in the scatter plot, one group consists of ``setosa'', 
and the other is formed by ``versicolor'' and ``virginica'', and the data for 
these two species are sort of messing up.

\subsection{Manipulating Data with \Rfunction{clues}}

In this section, we illustrate the usage of the function \Rfunction{clues}.
By applying this function on a targeted data set, we could obtain the final partition
result. An advantage of this function that makes it stand out from the others 
is that it does not require the input of the number of clusters. 
For \Robject{iris} data, when we apply function \Rfunction{clues} directly with 
\Rfunarg{strengthMethod}, which reflects the compactness of the clusters,
being \Rfunarg{sil}, we will get $2$ clusters. 
The first $50$ observations form one group and the rests form the second. 
Alternatively when \Rfunarg{CH} is selected as \Rfunarg{strengthMethod}, we will get $3$ groups instead. 
Still the first $50$ observations form the first group, 
group $2$ and $3$ are sort of mixing together. More details are provided as follows.
<<>>=
res.sil <- clues(dat.s, strengthMethod = "sil", disMethod = "Euclidean")
res.sil
res.CH <- clues(dat.s, strengthMethod = "CH", disMethod = "Euclidean")
res.CH
@

The clustering result from \Robject{res.sil} gives two reasonable groups shown in Figure~\ref{fig4}.
The average silhouette index appears to be $0.6867351$ which means that the partition is well done since it is 
not far from its upper limit $1$.  
Since groups $2$ and $3$ are partially overlapped, this leads to $15$ data points that belong to group $3$ 
being dragged to group $2$. The CH index appears to be $556.1177$ 
indicating that between group 
variation is $556.1177$ times of within group variation. Additionally, besides \Rfunarg{Euclidean}, 
\Rfunarg{1-corr} is also available as a \Rfunarg{disMethod}. However, for this type of data set, it turns out that
Euclidean distance works much better than $1-$ correlation.

\subsection{Visualizing Partition Result}

Now that we have obtained the clustering result, \Rpackage{clues} provides functions that 
can be applied to visualize it. Figures~\ref{fig4} and ~\ref{fig5} are obtained by function \Rfunction{plotClusters} and 
show graphical result with clusters distinguished by different plot symbols and colors.
The partition shown in Figure~\ref{fig4} is obtained when \Rfunarg{strengthMethod} is \Rfunarg{sil}, while 
the partition exhibited in Figure~\ref{fig5} is obtained when \Rfunarg{strengthMethod} is chosen to be \Rfunarg{CH}.
\begin{figure}[ht]
  \centering
<<fig = TRUE,width = 8,height = 8>>=
plotClusters(dat.s, res.sil$mem, plot.dim=1:4)
@
  \caption{Scatter plots for iris data after clustering using Silhouette index}
  \label{fig4}
\end{figure}
\begin{figure}[ht]
  \centering
<<fig = TRUE,width = 8,height = 8>>=
plotClusters(dat.s, res.CH$mem, plot.dim=1:4)
@
  \caption{Scatter plots for iris data after clustering using CH index}
  \label{fig5}
\end{figure}

Also function \Rfunction{plotAvgCurves} provides us a way to plot the average
trajectories for each existing cluster, shown in
Figure~\ref{fig6} and Figure~\ref{fig7}. 
\begin{figure}[ht]
  \centering
<<fig=TRUE,width=8,height=8>>=
plotAvgCurves(dat.s, res.sil$mem)
@
  \caption{Average trajectory plots for iris data after clustering using Silhouette index}
  \label{fig6}
\end{figure}
\begin{figure}[ht]
  \centering
<<fig=TRUE,width=8,height=8>>=
plotAvgCurves(dat.s, res.CH$mem)
@
  \caption{Average trajectory plots for iris data after clustering using CH index}
  \label{fig7}
\end{figure}


\subsection{Comparison Between Different Partition Methods}

To view similarities among the partitions 
derived from different clustering methods, function \Rfunction{compClust}, which calculates
mutual agreement indices for any pair of the methods considered,
gives decision makers useful insight, especially in the case when
the true membership is unknown. 
If different partitions are quite similar in terms of agreement
indices, the true cluster structure is at least separated and the
resulting clustering is fairly reliable. 
Numeric output of this function includes 
strength indices which consist of average Silhouette index and CH index, agreement
indices.

We compare \Rfunction{clues} with \Rfunction{kmeans} borrowed from package \Rpackage{stats} and \Rfunction{pam} 
borrowed from package \Rpackage{cluster}. Due to the blurred boundary, the true clusters
for \Robject{iris} can be treated either $2$ or $3$. We test the performances of clustering methods 
for both scenarios.
<<>>=
library(cluster)
library(stats)
iris.mem <- rep(1, dim(iris)[1])
iris.mem[iris$Species == "versicolor"] <- 2
iris.mem[iris$Species == "virginica"] <- 3
res.km <- kmeans(dat.s, 3, algorithm = "MacQueen")
res.pam <- pam(dat.s, 3)
memMat <- cbind(iris.mem, res.CH$mem, res.sil$mem, res.km$cluster, res.pam$clustering)
colnames(memMat) <- c("true", "clues.CH", "clues.sil", "km", "pam")
tt <- compClust(dat.s, memMat)
print(sapply(tt, function(x) { round(x, 2) }))
@

It is easy to see \Rfunction{clues} with \Rfunarg{CH} being the strength index has 
outstanding performance since it matches the true partition best in terms of any of these 
agreement indices given that the true number of clusters is $3$ where each species forms
its own group.
<<>>=
iris.mem1 <- rep(2, dim(iris)[1])
iris.mem1[iris$Species == "setosa"] <- 1
res.km1 <- kmeans(dat.s, 2, algorithm = "MacQueen")
res.pam1 <- pam(dat.s, 2)
memMat1 <- cbind(iris.mem1, res.CH$mem, res.sil$mem, res.km1$cluster, res.pam1$clustering)
colnames(memMat1) <- c("true", "clues.CH", "clues.sil", "km", "pam")
tt <- compClust(dat.s, memMat1)
print(sapply(tt, function(x) { round(x, 2) }))
@

When we assume the true number of groups to be $2$ where ``setosa'' forms
the first group and the rests are left as the second, method \Rfunction{clues}
with strength measure being \Rfunarg{sil} gives a perfect match to the true partition.
Methods \Rfunction{kmeans} and \Rfunction{pam} give slightly different results.

\subsection{Data Sharpening}

The function \Rfunction{shrinking} serves as a data sharpener.
<<>>=
shrinkres <- shrinking(dat.s, K = 60, disMethod = "Euclidean")
dimnames(shrinkres) <- dimnames(dat.s)
@
After data sharpening, pairwise scatter plot for the sharpened data is
presented in Figure~\ref{fig2}. 
\begin{figure}[ht]
  \centering
<<fig=TRUE,width=8,height=8>>=
pairs(shrinkres) 
@
  \caption{Scatter plots for sharpened iris data}
  \label{fig2}
\end{figure}

In the pairwise scatter plot for sharpened iris data set, three distinct data 
points are clearly seen which indicates there are $3$ distinct groups for the 
original data when we fix \Rfunarg{K} to be $60$. 

\section{Discussion}

In this vignette, we provide a rough guidance for a recently developed
clustering package \Rpackage{clues}. It is superior to commonly used partition algorithms 
by getting rid of necessity of prior information about the number of clusters. Some functions, 
such as \Rfunction{get\_CH}, \Rfunction{get\_Silhouette} and \Rfunction{CompClust} 
can be used as tools for evaluating new clustering methods in simulation study.

\section{References}

\refer Fisher, R.A., 1936. The Use of Multiple Measurements in Taxonomic Problems,
{\em Annals of Eugenics}, 7(2), 179-188.

\refer Wang, X.G., Qiu, W.L., and Zamar, R.H., 2007. 
CLUES: {A} Non-parametric Clustering Method Based on Local Shrinking,
{\em Computational Statistics \& Data Analysis}, 52(1), 286-298. 


\end{document}
